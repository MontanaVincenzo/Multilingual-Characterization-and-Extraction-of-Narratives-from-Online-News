{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1632,
     "status": "ok",
     "timestamp": 1736769063198,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "r7drESD5Xwj-",
    "outputId": "a77514b9-cc1f-471f-c9e4-ffe51fd8c0e1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1736769675904,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "ZaBMT6CxAddc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_data(file_path):\n",
    "  data = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"file_name\", \"entity\", \"start_offset\", \"end_offset\", \"label_0\", \"label_1\", \"label_2\", \"label_3\", \"label_4\", \"label_5\", \"label_6\", \"label_7\", \"label_8\", \"label_9\", \"label_10\", \"label_11\", \"label_12\"])\n",
    "\n",
    "  # Drop the first label column\n",
    "  data = data.drop(columns=[\"label_0\"])\n",
    "  data = data.sort_values(by=[\"file_name\", \"start_offset\"], ascending=[True, False])\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1736769677505,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "IOgAJiweqAnW"
   },
   "outputs": [],
   "source": [
    "# Load the file\n",
    "file_path_train = \"./Datasets/Train/EN/subtask-1-annotations.txt\"\n",
    "file_path_val = \"./Datasets/Development/EN/subtask-1-annotations.txt\"\n",
    "train_data = load_data(file_path_train)\n",
    "val_data = load_data(file_path_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1736769679112,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "3Wlc6-1UqPoe"
   },
   "outputs": [],
   "source": [
    "def add_special_tokens(entity_info, folder_path):\n",
    "    \"\"\"\n",
    "    Add special tokens to mark entities in the text based on their offsets.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the .txt file containing the text.\n",
    "        entity_info (list of dict): A list of dictionaries containing the entity offsets and labels.\n",
    "            Example:\n",
    "            [{\"start_offset\": 27, \"end_offset\": 40, \"entity\": \"lab-grown meat\"}]\n",
    "\n",
    "    Returns:\n",
    "        str: The modified text with special tokens.\n",
    "    \"\"\"\n",
    "        # Open and read the file content\n",
    "\n",
    "    with open(folder_path+\"/\"+entity_info[\"file_name\"], \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "\n",
    "    # Sort the entity_info by descending start_offset to avoid messing up offsets\n",
    "    #entity_info = sorted(entity_info, key=lambda x: x[\"start_offset\"], reverse=True)\n",
    "\n",
    "    # Add special tokens to each entity\n",
    "\n",
    "    start, end = entity_info[\"start_offset\"], entity_info[\"end_offset\"]\n",
    "    text = text[:start] + \"<T> \" + text[start:end+1] + \" </T>\" + text[end+1:]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1736769681778,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "16BqU_C9BJgl"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(data, folder_path):\n",
    "  dataset = []\n",
    "  for index, row in data.iterrows():\n",
    "    dict_entity = {\"file_name\": row[0], \"start_offset\": int(row[2]), \"end_offset\": int(row[3]), \"entity\": row[1]}\n",
    "    label_list = []\n",
    "    for i in range(4, 16):\n",
    "      if str(row[i]) != 'nan':\n",
    "        label_list.append(row[i])\n",
    "    dataset.append({\"text\": add_special_tokens(dict_entity, folder_path), \"textual_labels\": label_list})\n",
    "  return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2580,
     "status": "ok",
     "timestamp": 1736769686821,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "4q96OKrAqR4K",
    "outputId": "1d291257-bba2-4dbc-ca97-a3937f2d8561"
   },
   "outputs": [],
   "source": [
    "train_dataset = preprocess_dataset(train_data, \"./Datasets/Train/EN/raw-documents\")\n",
    "val_dataset = preprocess_dataset(val_data, \"./Datasets/Development/EN/subtask-1-documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736769072461,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "nj9PvWpFskro",
    "outputId": "79f4a4bc-c1eb-4903-95b0-8123310755bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Saboteur', 'Conspirator']\n",
      "['Bigot']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[54][\"textual_labels\"])\n",
    "print(val_dataset[2][\"textual_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1736769074020,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "T0mFWiJT7yIV"
   },
   "outputs": [],
   "source": [
    "taxonomy = [\n",
    "    \"Guardian\", \"Martyr\", \"Peacemaker\", \"Rebel\", \"Underdog\", \"Virtuous\",\n",
    "    \"Instigator\", \"Conspirator\", \"Tyrant\", \"Foreign Adversary\", \"Traitor\",\n",
    "    \"Spy\", \"Saboteur\", \"Corrupt\", \"Incompetent\", \"Terrorist\", \"Deceiver\",\n",
    "    \"Bigot\", \"Forgotten\", \"Exploited\", \"Victim\", \"Scapegoat\"\n",
    "]\n",
    "# Map labels to binary vectors\n",
    "def encode_labels(label_list, taxonomy):\n",
    "    return [1.0 if label in label_list else 0.0 for label in taxonomy]\n",
    "\n",
    "for sample in train_dataset:\n",
    "    sample[\"labels\"] = encode_labels(sample[\"textual_labels\"], taxonomy)\n",
    "for sample in val_dataset:\n",
    "    sample[\"labels\"] = encode_labels(sample[\"textual_labels\"], taxonomy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1736769666406,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "CE7Kdj-XiVgO",
    "outputId": "a56b3b1e-634d-4642-eccf-e586dd1149c2"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Path to the folder you want to remove\n",
    "folder_path = \"/content/results\"\n",
    "\n",
    "# Remove the folder and its contents\n",
    "shutil.rmtree(folder_path)\n",
    "\n",
    "print(f\"Folder {folder_path} has been removed.\")\n",
    "\n",
    "folder_path = \"/content/logs\"\n",
    "\n",
    "# Remove the folder and its contents\n",
    "shutil.rmtree(folder_path)\n",
    "\n",
    "print(f\"Folder {folder_path} has been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7184,
     "status": "ok",
     "timestamp": 1736759883202,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "thqb6kbi8-TR",
    "outputId": "b26c87f7-48cd-4d45-f49f-6623877e8a51"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1736769077929,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "KQGMalDl85Vo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "val_dataset = Dataset.from_list(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1736769044763,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "3p3aOCR9gF3J",
    "outputId": "3af2d4a6-5a2f-4b89-e370-738b73e472e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'textual_labels', 'labels'],\n",
      "    num_rows: 686\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e217eec91cc4443a8b25c35831048758",
      "57dcaae68c0046fdb0d147a78c78c4e8",
      "7628cb8aa25345fab7764d854a52e0ec",
      "491d9ce2937c4cd1b74a0e67bcf6101c",
      "2d8de53dfbbe4e5ab1db11c62aabce72",
      "192a03256c13423b992c84a41adc23bc",
      "1eaee25bb72141a1900d5b9c982c0f3c",
      "e62c2163d8974056a748405b198306c4",
      "8ebe91afa6134090a8d02e8e492fc98a",
      "aa2662f19cd1423db717858c2849732b",
      "6341f4d7dbd9444791b63a9aafe29e61",
      "c03d0164c7c8479abb241ae72a656236",
      "2ccc9c7565914c228d6dce05d5b6defd",
      "40dfcec4a9b847288083d11d7dbebdb3",
      "888dd4f39b304c48a910a5ed2d85ec96",
      "bd3dc671da984eeb871840ab2ec0e7c0",
      "66a78809367b4e349bae7422338dadab",
      "26624b54eb394549b7c751d502d11c80",
      "d89ea2b2963e4f3b90338dedbd7ca1ac",
      "1f021eb4ddcd4b3fb1e887c8cd4ff4be",
      "73dc9c34df9945399c8708dbfa646d0d",
      "045c614ddd364e06bbf79e524b5abdc0"
     ]
    },
    "executionInfo": {
     "elapsed": 9307,
     "status": "ok",
     "timestamp": 1736769556508,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "smmr-kVvfZB6",
    "outputId": "ca9f2972-90e0-412a-b5ef-468b4b606cfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 686/686 [00:00<00:00, 2676.99 examples/s]\n",
      "Map: 100%|██████████| 91/91 [00:00<00:00, 1021.43 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'input_ids': tensor([     0,  42673, 175107,      7, 101057,   9624,     14, 116071, 110196,\n",
      "           271,     70, 140978,    214,    111,    581,    481,  15130,      7,\n",
      "             6,  63588,  61692,    397,  61661, 208585,    294,  11507,  64163,\n",
      "         61661,  35602, 113786,  24639,  48026,   8545,  23373,  75018,  35213,\n",
      "         23186,  31766,  23373,  14688,    159,  56564,  83435,  23373,  29971,\n",
      "        145688,    313, 187273,   8241,  14452,  42673, 160641,    621,  35971,\n",
      "         26866,      7,   3934,   2363,  10002,  44540,    136, 163684,    214,\n",
      "            70,  48800,  20288,  40059,    214, 125861,      7,      5,  42673,\n",
      "            83,   7730,     47,    186,     70,  11698,    111,     70,  39746,\n",
      "          7154,     47,     70, 153552,  15549,  17946,   7432,     23,     70,\n",
      "         17274,      5,      6,      5,   9563,  78684,   2685,    509,     10,\n",
      "          5155,    111,  22631,    390, 177500,      7,     47, 101630,   4034,\n",
      "            70,   6602,    111, 181952,   4420,      5,   1401,  92054,    297,\n",
      "            70,  17274,    509,   1660,  20949,  26859,    678,   2363,  39746,\n",
      "          7154,      4,    136,   3688,    642,    765,    442,      5,   2561,\n",
      "           214,  26866,      7,   3934,   2363,  10002,  44540,      4,  42673,\n",
      "        160641,    621, 163684,    214,  48800,   1602,    592, 125861,      7,\n",
      "             5,  14240,    450,     26,      7,  32233,  34923,     47,   1957,\n",
      "             5,  27766,   9319,  22631,   8622,    621,  53333, 203251, 112474,\n",
      "           100, 177500,      7,     47,   5646,     47,     70,  48800,      7,\n",
      "            23,  67842,   3173,      7,    111,  18782,      5,   4426,    618,\n",
      "          2740,  47231,      7,   5631,   1272,     19,      6,  42946,    618,\n",
      "          2740,    136,  23902,    621,  35971,     47,     70,  48800,      7,\n",
      "            98,  41626,     70,    702,    927,    111,  18982,      5,      4,\n",
      "         13794,    214,     99,  25134,   4205,     92,  43333,     23,   9020,\n",
      "             5,  47009,    142,  19732,   3129,   1556,  38516,     47,  79442,\n",
      "            10,  21334, 131126,    678, 117729,  38162,     23,   3395,    621,\n",
      "         20662,     70,  24745,   7565,   1295,    237,   2060,    237,  30749,\n",
      "            83,  35971,   3687,     23,  42673,     98,     70,    543,    927,\n",
      "           111,  22482,      5,   1650,     26,      7,   4552,  16877,    214,\n",
      "            47,   1957,     70,   3395,    111,     70,  17274,   5646,  26866,\n",
      "             7,   3934,   2363,  10002,  44540,      5,   3293,   6602,     83,\n",
      "         16487,     47,    186,   3643,  43824,    297,    678,  39746,   7154,\n",
      "            47,    581, 135987,     67,   1657,      5,  24812,     71, 154271,\n",
      "          1221,    186,  34475,     98,   2446,   4165,      4,  37301,    136,\n",
      "          2265,   2450,      5, 140682,   8230,    297,    100,     10,     45,\n",
      "         22372,    297,  18750, 140429,      5,   4263,    398,   3444,     47,\n",
      "          8060,     70,  78431,  26548,    581, 135987,     67,   1657,      4,\n",
      "         72090,  43032,   2046,  17203,     47,     70,    116,   2208,   2831,\n",
      "           111,    581, 135987,     67,   1657, 135078,      5,   3347,    398,\n",
      "           831,   3249,     10, 163117,   3688,      5,    581, 177106,    873,\n",
      "            11,   2271,  27331,     83,   5036,  71062,    214,     99,     10,\n",
      "         43573,  78643,  80973,  34515,      4,    136,    100,    903,    642,\n",
      "           621, 225876,    136, 102417,     38,   4966,    642,   8110,   2843,\n",
      "           186, 138155,      5,   1326,    361,   5369,    642,    765,    959,\n",
      "         37170,    100,   2499, 163117,      7,      4,    136,    765,  88303,\n",
      "           903,  13452,    678,   2446,  10002,   9458,      7,    237,    642,\n",
      "          3514,    434,      5,   1401,    621,   5036, 136303,     33,  21896,\n",
      "         17669, 118055, 105925,  24503,      7,   4743,     47,     70,  21334,\n",
      "         14012,    111,  64324,    136,  77635,    642,  33636,      5,   1061,\n",
      "           642,    765,   1660,  20600,    297, 163117,  77679,      7,     98,\n",
      "          2446,  64324,    136,  26458,    450,    398,  16916,    903,   3229,\n",
      "           398,  19922,   2856,      5, 182747,     83,   5792,  19336,      5,\n",
      "          1401,  51544,    398,    100,    756,    935,   8060,    136,    935,\n",
      "        177229,      7,    153,     15,  41445,    571,     16,  16277,  80042,\n",
      "            12,   1301,     10,  14375,    538,      6, 157272,   1467,   1764,\n",
      "             4,    642,  76875,     70,   7108,     47,  87388,      2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# Define the special tokens to add\n",
    "special_tokens_dict = {\n",
    "    \"additional_special_tokens\": [\"<T>\", \"</T>\"]\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=tokenizer.model_max_length\n",
    "    )\n",
    "    # Convert labels to float for each example in the batch\n",
    "    tokenized[\"labels\"] = [[float(x) for x in label_list] for label_list in examples[\"labels\"]]\n",
    "    return tokenized\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][\"labels\"][0])  # Should output a list of floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'input_ids': tensor([     0,  42673, 175107,      7, 101057,   9624,     14, 116071, 110196,\n",
      "           271,     70, 140978,    214,    111,    581,    481,  15130,      7,\n",
      "             6,  63588,  61692,    397,  61661, 208585,    294,  11507,  64163,\n",
      "         61661,  35602, 113786,  24639,  48026,   8545,  23373,  75018,  35213,\n",
      "         23186,  31766,  23373,  14688,    159,  56564,  83435,  23373,  29971,\n",
      "        145688,    313, 187273,   8241,  14452,  42673, 160641,    621,  35971,\n",
      "         26866,      7,   3934,   2363,  10002,  44540,    136, 163684,    214,\n",
      "            70,  48800,  20288,  40059,    214, 125861,      7,      5,  42673,\n",
      "            83,   7730,     47,    186,     70,  11698,    111,     70,  39746,\n",
      "          7154,     47,     70, 153552,  15549,  17946,   7432,     23,     70,\n",
      "         17274,      5,      6,      5,   9563,  78684,   2685,    509,     10,\n",
      "          5155,    111,  22631,    390, 177500,      7,     47, 101630,   4034,\n",
      "            70,   6602,    111, 181952,   4420,      5,   1401,  92054,    297,\n",
      "            70,  17274,    509,   1660,  20949,  26859,    678,   2363,  39746,\n",
      "          7154,      4,    136,   3688,    642,    765,    442,      5,   2561,\n",
      "           214,  26866,      7,   3934,   2363,  10002,  44540,      4,  42673,\n",
      "        160641,    621, 163684,    214,  48800,   1602,    592, 125861,      7,\n",
      "             5,  14240,    450,     26,      7,  32233,  34923,     47,   1957,\n",
      "             5,  27766,   9319,  22631,   8622,    621,  53333, 203251, 112474,\n",
      "           100, 177500,      7,     47,   5646,     47,     70,  48800,      7,\n",
      "            23,  67842,   3173,      7,    111,  18782,      5,   4426,    618,\n",
      "          2740,  47231,      7,   5631,   1272,     19,      6,  42946,    618,\n",
      "          2740,    136,  23902,    621,  35971,     47,     70,  48800,      7,\n",
      "            98,  41626,     70,    702,    927,    111,  18982,      5,      4,\n",
      "         13794,    214,     99,  25134,   4205,     92,  43333,     23,   9020,\n",
      "             5,  47009,    142,  19732,   3129,   1556,  38516,     47,  79442,\n",
      "            10,  21334, 131126,    678, 117729,  38162,     23,   3395,    621,\n",
      "         20662,     70,  24745,   7565,   1295,    237,   2060,    237,  30749,\n",
      "            83,  35971,   3687,     23,  42673,     98,     70,    543,    927,\n",
      "           111,  22482,      5,   1650,     26,      7,   4552,  16877,    214,\n",
      "            47,   1957,     70,   3395,    111,     70,  17274,   5646,  26866,\n",
      "             7,   3934,   2363,  10002,  44540,      5,   3293,   6602,     83,\n",
      "         16487,     47,    186,   3643,  43824,    297,    678,  39746,   7154,\n",
      "            47,    581, 135987,     67,   1657,      5,  24812,     71, 154271,\n",
      "          1221,    186,  34475,     98,   2446,   4165,      4,  37301,    136,\n",
      "          2265,   2450,      5, 140682,   8230,    297,    100,     10,     45,\n",
      "         22372,    297,  18750, 140429,      5,   4263,    398,   3444,     47,\n",
      "          8060,     70,  78431,  26548,    581, 135987,     67,   1657,      4,\n",
      "         72090,  43032,   2046,  17203,     47,     70,    116,   2208,   2831,\n",
      "           111,    581, 135987,     67,   1657, 135078,      5,   3347,    398,\n",
      "           831,   3249,     10, 163117,   3688,      5,    581, 177106,    873,\n",
      "            11,   2271,  27331,     83,   5036,  71062,    214,     99,     10,\n",
      "         43573,  78643,  80973,  34515,      4,    136,    100,    903,    642,\n",
      "           621, 225876,    136, 102417,     38,   4966,    642,   8110,   2843,\n",
      "           186, 138155,      5,   1326,    361,   5369,    642,    765,    959,\n",
      "         37170,    100,   2499, 163117,      7,      4,    136,    765,  88303,\n",
      "           903,  13452,    678,   2446,  10002,   9458,      7,    237,    642,\n",
      "          3514,    434,      5,   1401,    621,   5036, 136303,     33,  21896,\n",
      "         17669, 118055, 105925,  24503,      7,   4743,     47,     70,  21334,\n",
      "         14012,    111,  64324,    136,  77635,    642,  33636,      5,   1061,\n",
      "           642,    765,   1660,  20600,    297, 163117,  77679,      7,     98,\n",
      "          2446,  64324,    136,  26458,    450,    398,  16916,    903,   3229,\n",
      "           398,  19922,   2856,      5, 182747,     83,   5792,  19336,      5,\n",
      "          1401,  51544,    398,    100,    756,    935,   8060,    136,    935,\n",
      "        177229,      7,    153,     15,  41445,    571,     16,  16277,  80042,\n",
      "            12,   1301,     10,  14375,    538,      6, 157272,   1467,   1764,\n",
      "             4,    642,  76875,     70,   7108,     47,  87388,      2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1736769558695,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "-H1OxO68gYjO",
    "outputId": "f2b3c159-f003-4bd5-82d3-74be5ecf40f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(250002, 768, padding_idx=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\",\n",
    "    num_labels=len(taxonomy),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1736769560817,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "KnTg2778ht9b",
    "outputId": "6e0f95bf-b3f5-43c1-c250-45cb094dcb07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    save_steps=500,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1736769563100,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "vXsxuZINhy2J",
    "outputId": "2c8c152d-43dd-403f-f460-63668a1dd814"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\AppData\\Local\\Temp\\ipykernel_10824\\4210982979.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from scipy.special import expit  # Sigmoid\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute exact match ratio for multilabel classification.\n",
    "\n",
    "    Parameters:\n",
    "        pred: Tuple containing logits and labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the exact match ratio and chosen threshold.\n",
    "    \"\"\"\n",
    "    logits, labels = pred\n",
    "\n",
    "    # Apply sigmoid to convert logits to probabilities\n",
    "    probabilities = expit(logits)\n",
    "\n",
    "    # Compute optimal threshold using precision-recall curve\n",
    "    precisions, recalls, thresholds = precision_recall_curve(labels.ravel(), probabilities.ravel())\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "    # Convert probabilities to binary predictions using the chosen threshold\n",
    "    predictions = (probabilities > best_threshold).astype(int)\n",
    "\n",
    "    # Calculate exact match ratio\n",
    "    exact_match = np.all(predictions == labels, axis=1).mean()\n",
    "\n",
    "    return {\"exact_match_ratio\": exact_match, \"best_threshold\": best_threshold}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "executionInfo": {
     "elapsed": 891,
     "status": "error",
     "timestamp": 1736769567883,
     "user": {
      "displayName": "Vincenzo Montana",
      "userId": "02325560459874877468"
     },
     "user_tz": -60
    },
    "id": "KBpAktmUh-0p",
    "outputId": "06059466-846f-4895-a7f0-d3a665c6026b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/129 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\transformers\\trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2479\u001b[0m )\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2487\u001b[0m ):\n\u001b[0;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\transformers\\trainer.py:3579\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3579\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3581\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3584\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3585\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\transformers\\trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[1;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:1364\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1363\u001b[0m         loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n\u001b[1;32m-> 1364\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1367\u001b[0m     output \u001b[38;5;241m=\u001b[39m (logits,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\torch\\nn\\modules\\loss.py:725\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vince\\anaconda3\\envs\\RobotLearning\\lib\\site-packages\\torch\\nn\\functional.py:3195\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m   3193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "RobotLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "045c614ddd364e06bbf79e524b5abdc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "192a03256c13423b992c84a41adc23bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1eaee25bb72141a1900d5b9c982c0f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f021eb4ddcd4b3fb1e887c8cd4ff4be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "26624b54eb394549b7c751d502d11c80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ccc9c7565914c228d6dce05d5b6defd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66a78809367b4e349bae7422338dadab",
      "placeholder": "​",
      "style": "IPY_MODEL_26624b54eb394549b7c751d502d11c80",
      "value": "Map: 100%"
     }
    },
    "2d8de53dfbbe4e5ab1db11c62aabce72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40dfcec4a9b847288083d11d7dbebdb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d89ea2b2963e4f3b90338dedbd7ca1ac",
      "max": 91,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f021eb4ddcd4b3fb1e887c8cd4ff4be",
      "value": 91
     }
    },
    "491d9ce2937c4cd1b74a0e67bcf6101c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa2662f19cd1423db717858c2849732b",
      "placeholder": "​",
      "style": "IPY_MODEL_6341f4d7dbd9444791b63a9aafe29e61",
      "value": " 686/686 [00:04&lt;00:00, 154.97 examples/s]"
     }
    },
    "57dcaae68c0046fdb0d147a78c78c4e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_192a03256c13423b992c84a41adc23bc",
      "placeholder": "​",
      "style": "IPY_MODEL_1eaee25bb72141a1900d5b9c982c0f3c",
      "value": "Map: 100%"
     }
    },
    "6341f4d7dbd9444791b63a9aafe29e61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66a78809367b4e349bae7422338dadab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73dc9c34df9945399c8708dbfa646d0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7628cb8aa25345fab7764d854a52e0ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e62c2163d8974056a748405b198306c4",
      "max": 686,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ebe91afa6134090a8d02e8e492fc98a",
      "value": 686
     }
    },
    "888dd4f39b304c48a910a5ed2d85ec96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73dc9c34df9945399c8708dbfa646d0d",
      "placeholder": "​",
      "style": "IPY_MODEL_045c614ddd364e06bbf79e524b5abdc0",
      "value": " 91/91 [00:00&lt;00:00, 130.37 examples/s]"
     }
    },
    "8ebe91afa6134090a8d02e8e492fc98a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa2662f19cd1423db717858c2849732b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd3dc671da984eeb871840ab2ec0e7c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c03d0164c7c8479abb241ae72a656236": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ccc9c7565914c228d6dce05d5b6defd",
       "IPY_MODEL_40dfcec4a9b847288083d11d7dbebdb3",
       "IPY_MODEL_888dd4f39b304c48a910a5ed2d85ec96"
      ],
      "layout": "IPY_MODEL_bd3dc671da984eeb871840ab2ec0e7c0"
     }
    },
    "d89ea2b2963e4f3b90338dedbd7ca1ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e217eec91cc4443a8b25c35831048758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_57dcaae68c0046fdb0d147a78c78c4e8",
       "IPY_MODEL_7628cb8aa25345fab7764d854a52e0ec",
       "IPY_MODEL_491d9ce2937c4cd1b74a0e67bcf6101c"
      ],
      "layout": "IPY_MODEL_2d8de53dfbbe4e5ab1db11c62aabce72"
     }
    },
    "e62c2163d8974056a748405b198306c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
